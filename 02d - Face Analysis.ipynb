{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "version": "3.5.3-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detecting and Analyzing Faces\n",
        "\n",
        "Computer vision solutions often require an artificial intelligence (AI) solution to be able to detect, analyze, or identify human faces. or example, suppose the retail company Northwind Traders has decided to implement a \"smart store\", in which AI services monitor the store to identify customers requiring assistance, and direct employees to help them. One way to accomplish this is to perform facial detection and analysis - in other words, determine if there are any faces in the images, and if so analyze their features.\n",
        "\n",
        "<p style='text-align:center'><img src='./images/face_analysis.jpg' alt='A robot analyzing a face'/></p>\n",
        "\n",
        "## Use the Face cognitive service to detect faces\n",
        "\n",
        "Suppose the smart store system that Northwind Traders wants to create needs to be able to detect customers and analyze their facial features. In Microsoft Azure, you can use the **Face** cognitive service to do this.\n",
        "\n",
        "Let's start by creating a **Cognitive Services** resource in your Azure subscription.\n",
        "\n",
        "> **Note**: If you already have a Cognitive Services resource, just open its **Quick start** page in the Azure portal and copy its key and endpoint to the cell below. Otherwise, follow the steps below to create one.\n",
        "\n",
        "1. In another browser tab, open the Azure portal at https://portal.azure.com, signing in with your Microsoft account.\n",
        "2. Click the **&#65291;Create a resource** button, search for *Cognitive Services*, and create a **Cognitive Services** resource with the following settings:\n",
        "    - **Name**: *Enter a unique name*.\n",
        "    - **Subscription**: *Your Azure subscription*.\n",
        "    - **Location**: *Choose any available region*:\n",
        "    - **Pricing tier**: S0\n",
        "    - **Resource group**: *Create a resource group with a unique name*.\n",
        "3. Wait for deployment to complete. Then go to your cognitive services resource, and on the **Quick start** page, note the keys and endpoint. You will need these to connect to your cognitive services resource from client applications.\n",
        "4. Copy the **Key1** for your resource and paste it in the code below, replacing **YOUR_COG_KEY**.\n",
        "5. Copy the **endpoint** for your resource and and paste it in the code below, replacing **YOUR_COG_ENDPOINT**.\n",
        "6. Run the code in the cell below by clicking its green <span style=\"color:green\">&#9655</span> button (at the top left of the cell)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
        "\n",
        "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Now that you have a Cognitive Services resource, you can use the Face service to detect human faces in the store.\n",
        "\n",
        "Run the code cell below to see an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.cognitiveservices.vision.face import FaceClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "from helper_scripts import faces\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Create a face detection client.\n",
        "face_client = FaceClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Open an image\n",
        "image_path = os.path.join('data', 'faces', 'Shopper1.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# Detect faces\n",
        "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
        "\n",
        "# Display the faces (code in helper_scripts/faces.py)\n",
        "faces.show_faces(image_path, detected_faces)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Each detected face is assigned a unique ID, so your application can identify each individual face that was detected.\n",
        "\n",
        "Run the cell below to see the IDs for some more shopper faces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Open an image\n",
        "image_path = os.path.join('data', 'faces', 'Shopper2.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# Detect faces\n",
        "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
        "\n",
        "# Display the faces (code in helper_scripts/faces.py)\n",
        "faces.show_faces(image_path, detected_faces, show_id=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Analyze facial attributes\n",
        "\n",
        "The Face cognitive service can do much more than simply detect faces. It can also analyze facial features and expressions to suggest gender, age, and emotional state; For example, run the code below to analyze the facial attributes of a shopper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Open an image\n",
        "image_path = os.path.join('data', 'faces', 'Shopper3.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# Detect faces and specified facial attributes\n",
        "attributes = ['age', 'gender', 'smile', 'emotion']\n",
        "detected_faces = face_client.face.detect_with_stream(image=image_stream, return_face_attributes=attributes)\n",
        "\n",
        "# Display the faces (code in helper_scripts/faces.py)\n",
        "faces.show_faces(image_path, detected_faces, show_id=True)\n",
        "\n",
        "# print facial attributes (code in helper_scripts/faces.py)\n",
        "faces.print_face_attributes(detected_faces)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Based on the emotion scores detected for the customer in the image, she seems pretty happy with her shopping experience.\n",
        "\n",
        "## Find similar faces\n",
        "\n",
        "The face IDs that are created for each detected face are used to individually identify face detections. You can use these IDs to compare a detected face to previously detected faces and find faces with similar features.\n",
        "\n",
        "For example, run the cell below to compare the shopper in one image with shoppers in another, and find a matching face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the ID of the first face in image 1\n",
        "image_1_path = os.path.join('data', 'faces', 'Shopper3.jpg')\n",
        "image_1_stream = open(image_1_path, \"rb\")\n",
        "image_1_faces = face_client.face.detect_with_stream(image=image_1_stream)\n",
        "face_1 = image_1_faces[0]\n",
        "\n",
        "# Get the face IDs in a second image\n",
        "image_2_path = os.path.join('data', 'faces', 'Shopper1.jpg')\n",
        "image_2_stream = open(image_2_path, \"rb\")\n",
        "image_2_faces = face_client.face.detect_with_stream(image=image_2_stream)\n",
        "image_2_face_ids = list(map(lambda face: face.face_id, image_2_faces))\n",
        "\n",
        "# Find faces in image 2 that are similar to the one in image 1\n",
        "similar_faces = face_client.face.find_similar(face_id=face_1.face_id, face_ids=image_2_face_ids)\n",
        "\n",
        "# Show the face in image 1, and similar faces in image 2(code in helper_scripts/face.py)\n",
        "faces.show_similar_faces(image_1_path, face_1, image_2_path, image_2_faces, similar_faces)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Learn More\n",
        "\n",
        "The **Face** service can do a lot more than we've explored in this exercise, including the ability to create a database of known faces that can be used for *facial recognition*. This enables your AI application to identify specific individuals in photographs, or even to perform identity verification for biometric security systems.\n",
        "\n",
        "To learn more about the Face cognitive service, see the [Face documentation](https://docs.microsoft.com/azure/cognitive-services/face/)\n"
      ]
    }
  ]
}