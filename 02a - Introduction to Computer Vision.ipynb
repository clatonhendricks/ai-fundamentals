{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "version": "3.5.3-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Introduction to Computer Vision\n",
        "\n",
        "*Computer Vision* is a branch of artificial intelligence (AI) that explores the development of AI systems that can \"see\" the world, either in real-time through a camera or by analyzing images and video. This is made possible by the fact that digital images are essentially just arrays of numeric pixel values, and we can use those pixel values as *features* to train machine learning models that can classify images, detect discrete objects in an image, and even generate text-based summaries of a photographs.\n",
        "\n",
        "<p style='text-align:center'><img src='./images/computer_vision.jpg' alt='A robot with glasses'/></p>\n",
        "\n",
        "## Use the Computer Vision Cognitive Service\n",
        "\n",
        "Microsoft Azure includes a number of *cognitive services* that encapsulate common AI functions, including some that can help you build computer vision solutions.\n",
        "\n",
        "The *Computer Vision* cognitive service provides an obvious starting point for our exploration of computer vision in Azure. It uses pre-trained machine learning models to analyze images and extract information about them.\n",
        "\n",
        "For example, suppose Adventure Works Cycles has set up a number of cameras around the city to track the cycles that have been rented. By using the Computer Vision service, the images taken by the cameras can be analyzed to provide meaningful descriptions of what they depict.\n",
        "\n",
        "> **Citation**: The images used in this lab are from the [PASCAL Visual Object Classes (VOC) challenge dataset](http://host.robots.ox.ac.uk/pascal/VOC/voc2007/#citation).\n",
        ">\n",
        "> @misc{pascal-voc-2007,\n",
        "\tauthor = \"Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.\",\n",
        "\ttitle = \"The {PASCAL} {V}isual {O}bject {C}lasses {C}hallenge 2007 {(VOC2007)} {R}esults\",\n",
        "\thowpublished = \"http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html\"}\n",
        "\n",
        "Let's start by creating a **Cognitive Services** resource in your Azure subscription:\n",
        "\n",
        "1. In another browser tab, open the Azure portal at https://portal.azure.com, signing in with your Microsoft account.\n",
        "2. Click the **&#65291;Create a resource** button, search for *Cognitive Services*, and create a **Cognitive Services** resource with the following settings:\n",
        "    - **Name**: *Enter a unique name*.\n",
        "    - **Subscription**: *Your Azure subscription*.\n",
        "    - **Location**: *Choose any available region*:\n",
        "    - **Pricing tier**: S0\n",
        "    - **Resource group**: *Create a resource group with a unique name*.\n",
        "3. Wait for deployment to complete. Then go to your cognitive services resource, and on the **Quick start** page, note the keys and endpoint. You will need these to connect to your cognitive services resource from client applications.\n",
        "4. Copy the **Key1** for your resource and paste it in the code below, replacing **YOUR_COG_KEY**.\n",
        "5. Copy the **endpoint** for your resource and and paste it in the code below, replacing **YOUR_COG_ENDPOINT**.\n",
        "6. Run the code in the cell below by clicking its green <span style=\"color:green\">&#9655</span> button (at the top left of the cell)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
        "\n",
        "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Now that you've set up the key and endpoint, you can use the custom vision service to analyze an image.\n",
        "\n",
        "Run the following cell to get a description for an image in the */data/voc/2009_004642.jpg* file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Get a client for the computer vision service\n",
        "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Open an image and display it\n",
        "image_path = os.path.join('data', 'voc', '2009_004642.jpg')\n",
        "img = Image.open(image_path)\n",
        "plt.axis('off')\n",
        "plt.imshow(img)\n",
        "\n",
        "# Get a description from the computer vision service\n",
        "image_stream = open(image_path, \"rb\")\n",
        "description_results = computervision_client.describe_image_in_stream(image_stream )\n",
        "if (len(description_results.captions) == 0):\n",
        "    print(\"No description detected.\")\n",
        "else:\n",
        "    for caption in description_results.captions:\n",
        "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "The description provided seems to be pretty accurate.\n",
        "\n",
        "The Computer Vision cognitive service offers a lot more functionality than generating image descriptions, including:\n",
        "\n",
        "- Suggesting \"tags\" for images, which can be useful if you want to index a lot of images for searching.\n",
        "- Identifying celebrities or well-known landmarks in images.\n",
        "- Detecting brand logos in an image.\n",
        "- Performing optical character recognition (OCR) to read text in an image.\n",
        "- Detect adult content in an image."
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Use the Custom Vision Cognitive service\n",
        "\n",
        "The Computer Vision cognitive service provides useful pre-built models for working with images, but you'll often need to train your own model for computer vision. For example, suppose Adventure Works Cycles wants to use the cameras around the city to analyze traffic by identifying images of cars, buses, and cyclists. To do this, you'll need to train a *classification* model that can categorize images into these classes of road user.\n",
        "\n",
        "### Train an Image Classification Model\n",
        "You can use the *Custom Vision* cognitive service to train an image classification model based on existing images.\n",
        "\n",
        "1. Download and extract the training images from https://github.com/GraemeMalcolm/ai-fundamentals/raw/master/data/voc/training_images.zip.\n",
        "2. In another browser tab, open the Custom Vision portal(https://www.customvision.ai/projects). If prompted, sign in using the Microsoft account associated with your Azure subscription.\n",
        "3. In the Custom Vision portal, create a new project with the following settings:\n",
        "    - **Name**: Traffic Classification\n",
        "    - **Description**: Image classification for traffic.\n",
        "    - **Resource**: *The Cognitive Services resource you created previously*. If this is not listed, create and select a new resource with the following settings:\n",
        "        - **Name**: *A unique name*\n",
        "        - **Subscription**: *Your Azure subscription*\n",
        "        - **Resource Group**: *Select an existing resource group or create and select a new one*.\n",
        "        - **Kind**: Cognitive Services\n",
        "        - **Location**: *Any available location*\n",
        "        - **Pricing Tier**: S0\n",
        "    - **Project Types**: Classification\n",
        "    - **Classification Types**: Multiclass (single tag per image)\n",
        "    - **Domains**: General\n",
        "4. Click **\\[+\\] Add images**, and select all of the files in the **bus** folder you extracted previously. Then upload the image files, specifying the tag *bus*.\n",
        "5. Repeat the previous step to upload the images in the **car** folder with the tag *car*, and the images in the **cyclist** folder with the tag *cyclist*.\n",
        "6. Explore the images you have uploaded in the Custom Vision project - there should be 40 images of each class.\n",
        "7. In the Custom Vision project, click **Train** to train a classification model using the tagged images. Select the **Quick Training** option.\n",
        "8. Wait for training to complete, and then review the *Precision*, *Recall*, and **AP* performance metrics - these measure the prediction accuracy of the classification model, and should all be high.\n",
        "9. Click **&#128504; Publish** to publish the trained model with the following settings:\n",
        "    - **Model name**: traffic\n",
        "    - **Prediction Resource**: *Your cognitive services resource*.\n",
        "10. After publishing, click the **&#9881;** icon at the top right to view the project settings. Under **General** (on the left), note the **Project Id**; and under **Resources** (on the right)  note the **Key** and **Endpoint** values. Copy these values and paste them in the code cell below, replacing **YOUR_PROJECT_ID**, **YOUR_KEY** and **YOUR_ENDPOINT**.\n",
        "11. Run the code cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "project_id = 'YOUR_PROJECT_ID'\n",
        "cog_key = 'YOUR_KEY'\n",
        "cog_endpoint = 'YOUR_ENDPOINT'\n",
        "model_name = 'traffic' # this must match the model name you set when publishing your model iteration exactly (including case)!\n",
        "print('Ready to predict using model {} in project {}'.format(model_name, project_id))"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Now you're ready to use your custom vision classification model.\n",
        "\n",
        "Run the following code cell, which uses your model to classifiy a selection of test images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Get the test images from the data/voc/test folder\n",
        "test_folder = os.path.join('data', 'voc', 'test')\n",
        "test_images = os.listdir(test_folder)\n",
        "\n",
        "# Create an instance of the prediction service\n",
        "custom_vision_client = CustomVisionPredictionClient(cog_key, endpoint=cog_endpoint)\n",
        "\n",
        "# Create a figure to display the results\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "\n",
        "# Get the images and show the predicted classes\n",
        "for idx in range(len(test_images)):\n",
        "    # Open the image, and use the custom vision model to classify it\n",
        "    image_contents = open(os.path.join(test_folder, test_images[idx]), \"rb\")\n",
        "    classification = custom_vision_client.classify_image(project_id, model_name, image_contents.read())\n",
        "    # The results include a prediction for each tag, in descending order of probability - get the first one\n",
        "    prediction = classification.predictions[0].tag_name\n",
        "    # Display the image with its predicted class\n",
        "    img = Image.open(os.path.join(test_folder, test_images[idx]))\n",
        "    a=fig.add_subplot(len(test_images)/3, 3,idx+1)\n",
        "    a.axis('off')\n",
        "    imgplot = plt.imshow(img)\n",
        "    a.set_title(prediction)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "Hopefully, your image classification model has correctly identified the vehicles in the images.\n",
        "\n",
        "You can also use the Custom Vision service to create *object detection* models, which not only classify objects in images, but also identify *bounding boxes* that show the location of the object in the image."
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Using the Face Cognitive service\n",
        "\n",
        "You may have noticed that the Custom Vision model you trained actually identifies *cycles* rather than *cyclists*. It might be useful to extend the traffic analysis application to analyze images that are classified as *cyclist* to determine if they contain any human faces; and if so count the number of faces detected and highlight them in the image.\n",
        "\n",
        "To accomplish this, you'll use a third cognitive service that provides face detection and facial recognition capabilies.\n",
        "\n",
        "The code below performs the same image classification as previously, but now when a *cyclist* image is found, the code uses the **Face** cognitive service to detect faces in the image.\n",
        "\n",
        "Run the code cell below to see the results of this enhancement to the application."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
        "from azure.cognitiveservices.vision.face import FaceClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Get the test images from the data/voc/test folder\n",
        "test_folder = os.path.join('data', 'voc', 'test')\n",
        "test_images = os.listdir(test_folder)\n",
        "\n",
        "# Create a prediction client\n",
        "custom_vision_client = CustomVisionPredictionClient(cog_key, endpoint=cog_endpoint)\n",
        "\n",
        "# Create a face detection client.\n",
        "face_client = FaceClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Create a figure to display the results\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "\n",
        "# Get the images and show the predicted classes\n",
        "for idx in range(len(test_images)):\n",
        "    # Open the image, and use the custom vision model to classify it\n",
        "    image_contents = open(os.path.join(test_folder, test_images[idx]), \"rb\")\n",
        "    classification = custom_vision_client.classify_image(project_id, model_name, image_contents.read())\n",
        "    # The results include a prediction for each tag, in descending order of probability - get the first one\n",
        "    prediction = classification.predictions[0].tag_name\n",
        "    # Open the image so we can add it to the figure\n",
        "    img = Image.open(os.path.join(test_folder, test_images[idx]))\n",
        "\n",
        "    # If the image is a cyclist, detect faces\n",
        "    if prediction == 'cyclist':\n",
        "        image_stream = open(os.path.join(test_folder, test_images[idx]), \"rb\")\n",
        "        detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
        "        if detected_faces:\n",
        "            # If there are faces, how many?\n",
        "            num_faces = len(detected_faces)\n",
        "            prediction = prediction + ' (' + str(num_faces) + ' faces detected)'\n",
        "            # Draw a rectangle around each detected face\n",
        "            for face in detected_faces:\n",
        "                r = face.face_rectangle\n",
        "                bounding_box = ((r.left, r.top), (r.left + r.width, r.top + r.height))\n",
        "                draw = ImageDraw.Draw(img)\n",
        "                draw.rectangle(bounding_box, outline='magenta', width=5)\n",
        "\n",
        "    # Display the image with its predicted class and detected faces\n",
        "    a=fig.add_subplot(len(test_images)/3, 3,idx+1)\n",
        "    a.axis('off')\n",
        "    imgplot = plt.imshow(img)\n",
        "    a.set_title(prediction)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "The Face cognitive service can do much more than simply detect faces. It can also analyze facial features and expressions to suggest gender, age, and emotional state; and it can compare faces for similarity and be trained to recognize individual faces."
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Learn More\n",
        "\n",
        "- To learn more about the Computer Vision cognitive service, see the [Computer Vision documentation](https://docs.microsoft.com/azure/cognitive-services/computer-vision/)\n",
        "- To learn more about the Custom Vision cognitive service, view the [Custom Vision documentation](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/home)\n",
        "- To learn more about the Face cognitive service, see the [Face documentation](https://docs.microsoft.com/azure/cognitive-services/face/)\n"
      ]
    }
  ]
}